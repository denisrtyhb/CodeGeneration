{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/final_result.csv\")\n",
    "first = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def echo_header(msg: str):\n",
      "    print(f'''\n",
      "--- {msg} ---''')\n"
     ]
    }
   ],
   "source": [
    "print(first['ground_truth'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def echo_header(msg):\n",
      "    print(\"###\", msg)\n"
     ]
    }
   ],
   "source": [
    "print(first['simple_generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def echo_header(msg: str):\n",
      "    print(f'''\n",
      "--- {msg} ---''')\n",
      "\n",
      "def update_branch(c: Context):\n",
      "    echo_header(f'{msg_type.SYNC} Syncing branch with remote')\n",
      "    if (not branch_exists_on_remote(c)):\n",
      "        c.run('git push --set-upstream origin HEAD')\n",
      "    else:\n",
      "        print('Pulling')\n",
      "        c.run('git pull')\n",
      "        print('Pushing')\n",
      "        c.run('git push')\n",
      "\n",
      "def get_python_path(preferred_version: str) -> Optional[str]:\n",
      "    'Get path to python executable.'\n",
      "    preferred_version_path = shutil.which(f'python{preferred_version}')\n",
      "    if (preferred_version_path is not None):\n",
      "        return preferred_version_path\n",
      "    print(f'{msg_type.WARN}: python{preferred_version} not found, continuing with default python version')\n",
      "    return shutil.which('python')\n",
      "\n",
      "def is_uncommitted_changes(c: Context) -> bool:\n",
      "    git_status_result: Result = c.run('git status --porcelain', pty=NOT_WINDOWS, hide=True)\n",
      "    uncommitted_changes = (git_status_result.stdout!= '')\n",
      "    return uncommitted_changes\n",
      "\n",
      "def exclamation_amplification(text: str) -> float:\n",
      "    ep_count = text.count('!')\n",
      "    if (ep_count > 4):\n",
      "        ep_count = 4\n",
      "    ep_amplifier = (ep_count * 0.292)\n",
      "    return ep_amplifier\n"
     ]
    }
   ],
   "source": [
    "print(first['context_generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def echo_header(msg: str):\n",
      "    print(f'''\n",
      "--- {msg} ---''')\n"
     ]
    }
   ],
   "source": [
    "print(first['ground_truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb07f7ade69e46dcabae15ac82aa2592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a function that prints sum of two numbers\n",
      "\n",
      "I have a function that prints the sum of two numbers. I want to make it more efficient.\n",
      "\n",
      "def print_sum(a, b):\n",
      "    print(a + b)\n",
      "\n",
      "I want to make it more efficient.\n",
      "\n",
      "def print_sum(a, b):\n",
      "    print(a + b)\n",
      "\n",
      "I want to make it more efficient.\n",
      "\n",
      "def print_sum(a, b):\n",
      "    print(a + b)\n",
      "\n",
      "I want to make it more efficient.\n",
      "\n",
      "def print_sum(a, b):\n",
      "    print(a + b)\n",
      "\n",
      "I want to make it more efficient.\n",
      "\n",
      "def print_sum(a, b):\n",
      "    print(a + b)\n",
      "\n",
      "I want to make it more efficient.\n",
      "\n",
      "def print_sum(a, b):\n",
      "    print(a + b)\n",
      "\n",
      "I want to make it more efficient.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda:7\"\n",
    "model_path = \"ibm-granite/granite-3.1-1b-a400m-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# drop device_map if running on CPU\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=device)\n",
    "model.eval()\n",
    "# change input text as desired\n",
    "input_text = \"Here is a function that sums squares of elements of a list:\\n\"\n",
    "# tokenize the text\n",
    "input_tokens = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "# generate output tokens\n",
    "output = model.generate(**input_tokens,\n",
    "                        max_length=200)\n",
    "# decode output tokens into text\n",
    "output = tokenizer.batch_decode(output)\n",
    "# print output\n",
    "print(output[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAAFramework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
